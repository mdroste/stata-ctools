
  ___  ____  ____  ____  ____ ®
 /__    /   ____/   /   ____/      StataNow 18.5
___/   /   /___/   /   /___/       MP—Parallel Edition

 Statistics and Data Science       Copyright 1985-2023 StataCorp LLC
                                   StataCorp
                                   4905 Lakeway Drive
                                   College Station, Texas 77845 USA
                                   800-782-8272        https://www.stata.com
                                   979-696-4600        service@stata.com

Stata license: Unlimited-user 16-core network, expiring  2 Jul 2026
Serial number: 501909320077
  Licensed to: Michael Droste
               Stanford University GSB

Notes:
      1. Stata is running in batch mode.
      2. Unicode is supported; see help unicode_advice.
      3. More than 2 billion observations are allowed; see help obs_advice.
      4. Maximum number of variables is set to 5,000 but can be increased;
          see help set_maxvar.


Running /Users/Mike/Documents/Stata/profile.do ...

. do validate_csort.do 

. /****************************************************************************
> ***
>  * validate_csort.do
>  *
>  * Comprehensive validation tests for csort vs native sort
>  * Tests sorting functionality across various data types and scenarios
>  *
>  * Note: csort uses inherently stable radix sort, so we compare against
>  * Stata's "sort, stable" for exact matches.
>  ****************************************************************************
> **/
. 
. do "validate_setup.do"

. *============================================================================
> ===
. * PROGRAM: validate_setup.do
. * PURPOSE: Helper programs for validation
. *============================================================================
> ===
. 
. version 14.0

. clear all

. set more off

. set trace off

. 
. * Add build directory with ctools to adopath
. adopath + "../build"
  [1]  (BASE)      "/Applications/Stata/ado/base/"
  [2]  (SITE)      "/Applications/Stata/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/Mike/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/Mike/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "../build"

. 
. * Global counters
. global TESTS_PASSED = 0

. global TESTS_FAILED = 0

. global TESTS_TOTAL = 0

. 
. *----------------------------------------------------------------------------
> ---
. * Helper program to compare scalars with tolerance
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_scalar_equal

. program define assert_scalar_equal
  1.     args name val1 val2 tol testname
  2. 
.     if "`tol'" == "" local tol = 1e-6
  3. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  4. 
.     local diff = abs(`val1' - `val2')
  5.     * Handle exact match case (for integers like N)
.     if `diff' == 0 | `diff' < `tol' {
  6.         global TESTS_PASSED = $TESTS_PASSED + 1
  7.         di as result "  PASS: `testname' (`name' diff = " %12.2e `diff' ")
> "
  8.     }
  9.     else {
 10.         global TESTS_FAILED = $TESTS_FAILED + 1
 11.         di as error "  FAIL: `testname' (`name': `val1' vs `val2', diff = 
> " %12.2e `diff' ")"
 12.     }
 13. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper program to compare matrices
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_matrix_equal

. program define assert_matrix_equal
  1.     args mat1 mat2 tol testname
  2. 
.     if "`tol'" == "" local tol = 1e-6
  3. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  4. 
.     tempname diff
  5.     matrix `diff' = `mat1' - `mat2'
  6.     local maxdiff = 0
  7.     local rows = rowsof(`diff')
  8.     local cols = colsof(`diff')
  9.     forvalues i = 1/`rows' {
 10.         forvalues j = 1/`cols' {
 11.             local d = abs(`diff'[`i', `j'])
 12.             if `d' > `maxdiff' local maxdiff = `d'
 13.         }
 14.     }
 15. 
.     if `maxdiff' < `tol' {
 16.         global TESTS_PASSED = $TESTS_PASSED + 1
 17.         di as result "  PASS: `testname' (max diff = " %12.2e `maxdiff' ")
> "
 18.     }
 19.     else {
 20.         global TESTS_FAILED = $TESTS_FAILED + 1
 21.         di as error "  FAIL: `testname' (max diff = " %12.2e `maxdiff' ")"
 22.     }
 23. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper program to compare variables
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_var_equal

. program define assert_var_equal
  1.     args var1 var2 tol testname
  2. 
.     if "`tol'" == "" local tol = 1e-10
  3. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  4. 
.     quietly count if abs(`var1' - `var2') > `tol'
  5.     local ndiff = r(N)
  6. 
.     if `ndiff' == 0 {
  7.         global TESTS_PASSED = $TESTS_PASSED + 1
  8.         di as result "  PASS: `testname' (all values match)"
  9.     }
 10.     else {
 11.         global TESTS_FAILED = $TESTS_FAILED + 1
 12.         di as error "  FAIL: `testname' (`ndiff' values differ)"
 13.     }
 14. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper program to compare string variables
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_strvar_equal

. program define assert_strvar_equal
  1.     args var1 var2 testname
  2. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  3. 
.     quietly count if `var1' != `var2'
  4.     local ndiff = r(N)
  5. 
.     if `ndiff' == 0 {
  6.         global TESTS_PASSED = $TESTS_PASSED + 1
  7.         di as result "  PASS: `testname' (all values match)"
  8.     }
  9.     else {
 10.         global TESTS_FAILED = $TESTS_FAILED + 1
 11.         di as error "  FAIL: `testname' (`ndiff' values differ)"
 12.     }
 13. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper to check if two datasets are identical (with fallback to sorted comp
> arison)
. 
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_data_equal

. program define assert_data_equal
  1.     args file1 file2 testname
  2. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  3. 
.     preserve
  4.     capture quietly {
  5.         use "`file1'", clear
  6.         cf _all using "`file2'"
  7.     }
  8.     local rc = _rc
  9.     restore
 10. 
.     if `rc' == 0 {
 11.         global TESTS_PASSED = $TESTS_PASSED + 1
 12.         di as result "  PASS: `testname' (datasets identical)"
 13.     }
 14.     else {
 15.         * Try sorting both datasets by all variables before comparing
.         preserve
 16.         capture quietly {
 17.             use "`file1'", clear
 18.             ds
 19.             local allvars `r(varlist)'
 20.             sort `allvars'
 21.             tempfile sorted1
 22.             save `sorted1', replace
 23. 
.             use "`file2'", clear
 24.             sort `allvars'
 25.             cf _all using `sorted1'
 26.         }
 27.         local rc2 = _rc
 28.         restore
 29. 
.         if `rc2' == 0 {
 30.             global TESTS_PASSED = $TESTS_PASSED + 1
 31.             di as result "  PASS: `testname' (datasets identical after sor
> ting)"
 32.         }
 33.         else {
 34.             global TESTS_FAILED = $TESTS_FAILED + 1
 35.             di as error "  FAIL: `testname' (datasets differ even after so
> rting)"
 36.         }
 37.     }
 38. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper to compare datasets after sorting (merges where row order may differ
> )
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_data_equal_sorted

. program define assert_data_equal_sorted
  1.     args file1 file2 sortkey testname
  2. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  3. 
.     preserve
  4.     quietly {
  5.         * Load and sort first file
.         use "`file1'", clear
  6.         sort `sortkey', stable
  7.         tempfile sorted1
  8.         save `sorted1'
  9. 
.         * Load and sort second file
.         use "`file2'", clear
 10.         sort `sortkey', stable
 11.         tempfile sorted2
 12.         save `sorted2'
 13. 
.         * Compare
.         use `sorted1', clear
 14.         cf _all using `sorted2'
 15.     }
 16.     local rc = _rc
 17.     restore
 18. 
.     if `rc' == 0 {
 19.         global TESTS_PASSED = $TESTS_PASSED + 1
 20.         di as result "  PASS: `testname' (datasets identical after sorting
> )"
 21.     }
 22.     else {
 23.         global TESTS_FAILED = $TESTS_FAILED + 1
 24.         di as error "  FAIL: `testname' (datasets differ even after sortin
> g)"
 25.     }
 26. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper to compare merge counts (merges where row order may differ)
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop assert_merge_counts_equal

. program define assert_merge_counts_equal
  1.     args file1 file2 testname
  2. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  3. 
.     preserve
  4.     quietly {
  5.         use "`file1'", clear
  6.         local n1 = _N
  7.         count if _merge == 1
  8.         local m1_1 = r(N)
  9.         count if _merge == 2
 10.         local m1_2 = r(N)
 11.         count if _merge == 3
 12.         local m1_3 = r(N)
 13. 
.         use "`file2'", clear
 14.         local n2 = _N
 15.         count if _merge == 1
 16.         local m2_1 = r(N)
 17.         count if _merge == 2
 18.         local m2_2 = r(N)
 19.         count if _merge == 3
 20.         local m2_3 = r(N)
 21.     }
 22.     restore
 23. 
.     local pass = (`n1' == `n2') & (`m1_1' == `m2_1') & (`m1_2' == `m2_2') & (
> `m1_3' == `m2_3')
 24. 
.     if `pass' {
 25.         global TESTS_PASSED = $TESTS_PASSED + 1
 26.         di as result "  PASS: `testname' (N=`n1', m1=`m1_1', m2=`m1_2', m3
> =`m1_3')"
 27.     }
 28.     else {
 29.         global TESTS_FAILED = $TESTS_FAILED + 1
 30.         di as error "  FAIL: `testname' counts differ"
 31.         di as error "    Stata: N=`n1', m1=`m1_1', m2=`m1_2', m3=`m1_3'"
 32.         di as error "    cmerge: N=`n2', m1=`m2_1', m2=`m2_2', m3=`m2_3'"
 33.     }
 34. end

. 
. *----------------------------------------------------------------------------
> ---
. * Helper program to print section header
. *----------------------------------------------------------------------------
> ---
. 
. capture program drop print_section

. program define print_section
  1.     args title
  2.     di as text ""
  3.     di as text "{hline 70}"
  4.     di as text "`title'"
  5.     di as text "{hline 70}"
  6. end

. 
. * Helper program to print test summary
. capture program drop print_summary

. program define print_summary
  1.     args component
  2.     di as text ""
  3.     di as text "{hline 70}"
  4.     di as text "SUMMARY: `component'"
  5.     di as text "{hline 70}"
  6.     di as text "Tests passed: " as result $TESTS_PASSED
  7.     di as text "Tests failed: " as result $TESTS_FAILED
  8.     di as text "Total tests:  " as result $TESTS_TOTAL
  9.     if $TESTS_FAILED > 0 {
 10.         di as error "VALIDATION FAILED"
 11.     }
 12.     else {
 13.         di as result "ALL TESTS PASSED"
 14.     }
 15.     di as text "{hline 70}"
 16. end

. 
. * Load benchmark helper programs
. do "benchmark_helpers.do"

. /****************************************************************************
> ***
>  * benchmark_helpers.do
>  *
>  * Benchmark helper programs for ctools validation test suite
>  * Each program runs both ctools and Stata native commands, compares results,
>  * and reports PASS/FAIL in a concise format.
>  *
>  * Usage:
>  *   benchmark_sort varlist [, options]
>  *   benchmark_merge mergetype keyvar using filename [, options]
>  *   benchmark_reghdfe depvar indepvars, absorb(varlist) [options]
>  *   benchmark_qreg depvar indepvars [, options]
>  *   benchmark_import using filename [, options]
>  *   benchmark_export using filename [, options]
>  ****************************************************************************
> **/
. 
. /****************************************************************************
> ***
>  * benchmark_sort
>  *
>  * Compare csort vs sort, stable
>  *
>  * Syntax: benchmark_sort varlist [, testname(string) algorithm(string)]
>  *
>  * Example:
>  *   sysuse auto, clear
>  *   benchmark_sort price
>  *   benchmark_sort foreign rep78, testname("multi-var sort")
>  *   benchmark_sort price, algorithm(msd)
>  *   benchmark_sort price, algorithm(timsort)
>  ****************************************************************************
> **/
. capture program drop benchmark_sort

. program define benchmark_sort
  1.     syntax varlist [, testname(string) ALGorithm(string)]
  2. 
.     if "`testname'" == "" local testname "sort `varlist'"
  3.     if "`algorithm'" != "" local testname "`testname' [alg=`algorithm']"
  4. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  5. 
.     preserve
  6. 
.     * Save original data
.     tempfile original
  7.     quietly save `original'
  8. 
.     * Run Stata sort, stable
.     sort `varlist', stable
  9.     tempfile stata_sorted
 10.     quietly save `stata_sorted'
 11. 
.     * Restore and run csort
.     use `original', clear
 12.     if "`algorithm'" != "" {
 13.         csort `varlist', algorithm(`algorithm')
 14.     }
 15.     else {
 16.         csort `varlist'
 17.     }
 18. 
.     * Compare datasets
.     capture quietly cf _all using `stata_sorted'
 19.     local rc = _rc
 20. 
.     restore
 21. 
.     if `rc' == 0 {
 22.         global TESTS_PASSED = $TESTS_PASSED + 1
 23.         di as result "[PASS] `testname'"
 24.     }
 25.     else {
 26.         global TESTS_FAILED = $TESTS_FAILED + 1
 27.         di as error "[FAIL] `testname'"
 28.     }
 29. end

. 
. /****************************************************************************
> ***
>  * benchmark_sort_all_algs
>  *
>  * Run benchmark_sort with all three algorithms (lsd, msd, timsort)
>  *
>  * Syntax: benchmark_sort_all_algs varlist [, testname(string)]
>  *
>  * Example:
>  *   benchmark_sort_all_algs price, testname("numeric sort")
>  ****************************************************************************
> **/
. capture program drop benchmark_sort_all_algs

. program define benchmark_sort_all_algs
  1.     syntax varlist [, testname(string)]
  2. 
.     if "`testname'" == "" local testname "sort `varlist'"
  3. 
.     * Test all three algorithms
.     benchmark_sort `varlist', testname("`testname'") algorithm(lsd)
  4.     benchmark_sort `varlist', testname("`testname'") algorithm(msd)
  5.     benchmark_sort `varlist', testname("`testname'") algorithm(timsort)
  6. end

. 
. /****************************************************************************
> ***
>  * benchmark_merge
>  *
>  * Compare cmerge vs merge
>  * Validates: (1) _merge counts match, (2) datasets are identical via cf _all
>  *
>  * Syntax: benchmark_merge mergetype keyvar using filename [, keep(string)
>  *         generate(string) nogenerate keepusing(varlist) testname(string)]
>  *
>  * Example:
>  *   benchmark_merge 1:1 id using mydata.dta
>  *   benchmark_merge m:1 foreign using lookup.dta, keep(match)
>  ****************************************************************************
> **/
. capture program drop benchmark_merge

. program define benchmark_merge
  1.     syntax anything using/, [keep(string) GENerate(name) NOGENerate KEEPUS
> ing(string) ///
>         testname(string) SORTed ASSert(string) UPDATE REPLACE FORCE NOLabel N
> ONotes]
  2. 
.     * Parse merge type and key vars
.     gettoken mergetype keyvars : anything
  3. 
.     if "`testname'" == "" local testname "merge `mergetype' `keyvars'"
  4. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  5. 
.     * Build option string
.     local opts ""
  6.     if "`keep'" != "" local opts "`opts' keep(`keep')"
  7.     if "`generate'" != "" local opts "`opts' generate(`generate')"
  8.     if "`nogenerate'" != "" local opts "`opts' nogenerate"
  9.     if "`keepusing'" != "" local opts "`opts' keepusing(`keepusing')"
 10.     if "`sorted'" != "" local opts "`opts' sorted"
 11.     if "`assert'" != "" local opts "`opts' assert(`assert')"
 12.     if "`update'" != "" local opts "`opts' update"
 13.     if "`replace'" != "" local opts "`opts' replace"
 14.     if "`force'" != "" local opts "`opts' force"
 15.     if "`nolabel'" != "" local opts "`opts' nolabel"
 16.     if "`nonotes'" != "" local opts "`opts' nonotes"
 17. 
.     preserve
 18. 
.     * Save original data
.     tempfile original
 19.     quietly save `original'
 20. 
.     * Run Stata merge
.     merge `mergetype' `keyvars' using `using', `opts'
 21. 
.     * Get _merge counts from Stata
.     capture confirm variable _merge
 22.     if _rc == 0 {
 23.         quietly count if _merge == 1
 24.         local stata_m1 = r(N)
 25.         quietly count if _merge == 2
 26.         local stata_m2 = r(N)
 27.         quietly count if _merge == 3
 28.         local stata_m3 = r(N)
 29.     }
 30.     else {
 31.         local stata_m1 = .
 32.         local stata_m2 = .
 33.         local stata_m3 = .
 34.     }
 35. 
.     * Save unsorted for first comparison
.     tempfile stata_merged_unsorted
 36.     quietly save `stata_merged_unsorted'
 37. 
.     * Sort by ALL variables for deterministic comparison
.     * (keyvars alone may leave order undefined within key groups)
.     qui ds
 38.     local allvars `r(varlist)'
 39.     sort `allvars'
 40.     tempfile stata_merged_sorted
 41.     quietly save `stata_merged_sorted'
 42. 
.     * Restore and run cmerge
.     use `original', clear
 43.     cmerge `mergetype' `keyvars' using `using', `opts'
 44. 
.     * Get _merge counts from cmerge
.     capture confirm variable _merge
 45.     if _rc == 0 {
 46.         quietly count if _merge == 1
 47.         local cmerge_m1 = r(N)
 48.         quietly count if _merge == 2
 49.         local cmerge_m2 = r(N)
 50.         quietly count if _merge == 3
 51.         local cmerge_m3 = r(N)
 52.     }
 53.     else {
 54.         local cmerge_m1 = .
 55.         local cmerge_m2 = .
 56.         local cmerge_m3 = .
 57.     }
 58. 
.     * Check 1: _merge counts match
.     local counts_match = 1
 59.     if `stata_m1' != `cmerge_m1' | `stata_m2' != `cmerge_m2' | `stata_m3' 
> != `cmerge_m3' {
 60.         local counts_match = 0
 61.     }
 62. 
.     * Check 2a: cf _all BEFORE sorting (tests if order is identical too)
.     capture quietly cf _all using `stata_merged_unsorted'
 63.     local cf_unsorted_rc = _rc
 64. 
.     * Check 2b: cf _all AFTER sorting by ALL variables (tests content only)
.     qui ds
 65.     local allvars `r(varlist)'
 66.     sort `allvars'
 67.     capture quietly cf _all using `stata_merged_sorted'
 68.     local cf_sorted_rc = _rc
 69. 
.     restore
 70. 
.     * Report results
.     if `counts_match' & `cf_sorted_rc' == 0 {
 71.         global TESTS_PASSED = $TESTS_PASSED + 1
 72.         if `cf_unsorted_rc' == 0 {
 73.             di as result "[PASS] `testname'"
 74.         }
 75.         else {
 76.             di as result "[PASS] `testname' (sort order differs)"
 77.         }
 78.     }
 79.     else {
 80.         global TESTS_FAILED = $TESTS_FAILED + 1
 81.         if !`counts_match' {
 82.             di as error "[FAIL] `testname' (_merge counts: m1:`stata_m1'!=
> `cmerge_m1' m2:`stata_m2'!=`cmerge_m2' m3:`stata_m3'!=`cmerge_m3')"
 83.         }
 84.         else {
 85.             di as error "[FAIL] `testname' (cf _all: datasets differ even 
> after sorting)"
 86.         }
 87.     }
 88. end

. 
. /****************************************************************************
> ***
>  * benchmark_reghdfe
>  *
>  * Compare creghdfe vs reghdfe
>  *
>  * Syntax: benchmark_reghdfe depvar indepvars [weight], absorb(varlist)
>  *         [vce(string) testname(string) tol(real)]
>  *
>  * Example:
>  *   benchmark_reghdfe price mpg weight, absorb(foreign)
>  *   benchmark_reghdfe y x1 x2 [aw=w], absorb(firm year) vce(cluster firm)
>  ****************************************************************************
> **/
. capture program drop benchmark_reghdfe

. program define benchmark_reghdfe
  1.     syntax varlist(min=2 fv) [aw fw pw] [if] [in], Absorb(varlist) [vce(st
> ring) testname(string) tol(real 1e-6)]
  2. 
.     gettoken depvar indepvars : varlist
  3. 
.     if "`testname'" == "" local testname "reghdfe `depvar' ... , absorb(`abso
> rb')"
  4. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  5. 
.     * Build weight string
.     local wtexp ""
  6.     if "`weight'" != "" local wtexp "[`weight'`exp']"
  7. 
.     * Build vce option
.     local vceopt ""
  8.     if "`vce'" != "" local vceopt "vce(`vce')"
  9. 
.     preserve
 10. 
.     * Run reghdfe
.     quietly reghdfe `depvar' `indepvars' `wtexp' `if' `in', absorb(`absorb') 
> `vceopt'
 11.     matrix reghdfe_b = e(b)
 12.     local reghdfe_N = e(N)
 13. 
.     * Run creghdfe
.     quietly creghdfe `depvar' `indepvars' `wtexp' `if' `in', absorb(`absorb')
>  `vceopt'
 14.     matrix creghdfe_b = e(b)
 15.     local creghdfe_N = e(N)
 16. 
.     restore
 17. 
.     * Compare N
.     if `reghdfe_N' != `creghdfe_N' {
 18.         global TESTS_FAILED = $TESTS_FAILED + 1
 19.         di as error "[FAIL] `testname' (N: `reghdfe_N' != `creghdfe_N')"
 20.         exit
 21.     }
 22. 
.     * Compare coefficients
.     tempname diff
 23.     matrix `diff' = reghdfe_b - creghdfe_b
 24.     local cols = colsof(`diff')
 25.     local maxdiff = 0
 26.     forvalues j = 1/`cols' {
 27.         local d = abs(`diff'[1, `j'])
 28.         if `d' > `maxdiff' local maxdiff = `d'
 29.     }
 30. 
.     if `maxdiff' < `tol' {
 31.         global TESTS_PASSED = $TESTS_PASSED + 1
 32.         di as result "[PASS] `testname'"
 33.     }
 34.     else {
 35.         global TESTS_FAILED = $TESTS_FAILED + 1
 36.         di as error "[FAIL] `testname' (max coef diff: " %9.2e `maxdiff' "
> )"
 37.     }
 38. end

. 
. /****************************************************************************
> ***
>  * benchmark_qreg
>  *
>  * Compare cqreg vs qreg
>  *
>  * Syntax: benchmark_qreg depvar indepvars [, quantile(real) vce(string)
>  *         testname(string) tol(real)]
>  *
>  * Example:
>  *   benchmark_qreg price mpg weight
>  *   benchmark_qreg price mpg weight, quantile(0.25)
>  ****************************************************************************
> **/
. capture program drop benchmark_qreg

. program define benchmark_qreg
  1.     syntax varlist(min=2 fv) [if] [in], [Quantile(real 0.5) vce(string) te
> stname(string) tol(real 1e-6)]
  2. 
.     gettoken depvar indepvars : varlist
  3. 
.     if "`testname'" == "" local testname "qreg `depvar' ... , q(`quantile')"
  4. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  5. 
.     * Build vce option
.     local vceopt ""
  6.     if "`vce'" != "" local vceopt "vce(`vce')"
  7. 
.     preserve
  8. 
.     * Run qreg
.     quietly qreg `depvar' `indepvars' `if' `in', quantile(`quantile') `vceopt
> '
  9.     matrix qreg_b = e(b)
 10.     local qreg_N = e(N)
 11. 
.     * Run cqreg
.     quietly cqreg `depvar' `indepvars' `if' `in', quantile(`quantile') `vceop
> t'
 12.     matrix cqreg_b = e(b)
 13.     local cqreg_N = e(N)
 14. 
.     restore
 15. 
.     * Compare N
.     if `qreg_N' != `cqreg_N' {
 16.         global TESTS_FAILED = $TESTS_FAILED + 1
 17.         di as error "[FAIL] `testname' (N: `qreg_N' != `cqreg_N')"
 18.         exit
 19.     }
 20. 
.     * Compare coefficients
.     tempname diff
 21.     matrix `diff' = qreg_b - cqreg_b
 22.     local cols = colsof(`diff')
 23.     local maxdiff = 0
 24.     forvalues j = 1/`cols' {
 25.         local d = abs(`diff'[1, `j'])
 26.         if `d' > `maxdiff' local maxdiff = `d'
 27.     }
 28. 
.     if `maxdiff' < `tol' {
 29.         global TESTS_PASSED = $TESTS_PASSED + 1
 30.         di as result "[PASS] `testname'"
 31.     }
 32.     else {
 33.         global TESTS_FAILED = $TESTS_FAILED + 1
 34.         di as error "[FAIL] `testname' (max coef diff: " %9.2e `maxdiff' "
> )"
 35.     }
 36. end

. 
. /****************************************************************************
> ***
>  * benchmark_import
>  *
>  * Compare cimport delimited vs import delimited
>  *
>  * Syntax: benchmark_import using filename [, delimiters(string) varnames(str
> ing)
>  *         case(string) rowrange(string) testname(string)]
>  *
>  * Example:
>  *   benchmark_import using "data.csv"
>  *   benchmark_import using "data.tsv", delimiters(tab)
>  ****************************************************************************
> **/
. capture program drop benchmark_import

. program define benchmark_import
  1.     syntax using/, [DELIMiters(string) VARNames(string) CASE(string) ROWRa
> nge(string) testname(string) clear]
  2. 
.     if "`testname'" == "" local testname "import `using'"
  3. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  4. 
.     * Build option string
.     local opts "clear"
  5.     if "`delimiters'" != "" local opts "`opts' delimiters(`delimiters')"
  6.     if "`varnames'" != "" local opts "`opts' varnames(`varnames')"
  7.     if "`case'" != "" local opts "`opts' case(`case')"
  8.     if "`rowrange'" != "" local opts "`opts' rowrange(`rowrange')"
  9. 
.     preserve
 10. 
.     * Run Stata import
.     import delimited `using', `opts'
 11.     local stata_n = _N
 12.     local stata_k = c(k)
 13.     tempfile stata_import
 14.     quietly save `stata_import'
 15. 
.     * Run cimport
.     cimport delimited `using', `opts'
 16.     local cimport_n = _N
 17.     local cimport_k = c(k)
 18. 
.     restore
 19. 
.     * Compare dimensions
.     if `stata_n' == `cimport_n' & `stata_k' == `cimport_k' {
 20.         global TESTS_PASSED = $TESTS_PASSED + 1
 21.         di as result "[PASS] `testname' (N=`stata_n', K=`stata_k')"
 22.     }
 23.     else {
 24.         global TESTS_FAILED = $TESTS_FAILED + 1
 25.         di as error "[FAIL] `testname' (N: `stata_n'!=`cimport_n', K: `sta
> ta_k'!=`cimport_k')"
 26.     }
 27. end

. 
. /****************************************************************************
> ***
>  * benchmark_export
>  *
>  * Compare cexport delimited vs export delimited
>  *
>  * Syntax: benchmark_export [varlist] using filename [, delimiter(string)
>  *         novarnames quote testname(string)]
>  *
>  * Example:
>  *   benchmark_export using "output.csv", replace
>  *   benchmark_export price mpg using "output.csv", replace
>  ****************************************************************************
> **/
. capture program drop benchmark_export

. program define benchmark_export
  1.     syntax [varlist] using/, [DELIMiter(string) NOVARNames QUOTE replace t
> estname(string)]
  2. 
.     if "`testname'" == "" local testname "export `using'"
  3. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  4. 
.     * Build option string
.     local opts "replace"
  5.     if "`delimiter'" != "" local opts "`opts' delimiter(`delimiter')"
  6.     if "`novarnames'" != "" local opts "`opts' novarnames"
  7.     if "`quote'" != "" local opts "`opts' quote"
  8. 
.     preserve
  9. 
.     * Generate temp filenames
.     tempfile stata_export cexport_export
 10.     local stata_csv = subinstr("`stata_export'", ".dta", ".csv", .)
 11.     local cexport_csv = subinstr("`cexport_export'", ".dta", ".csv", .)
 12. 
.     * Run Stata export
.     if "`varlist'" != "" {
 13.         export delimited `varlist' using "`stata_csv'", `opts'
 14.     }
 15.     else {
 16.         export delimited using "`stata_csv'", `opts'
 17.     }
 18. 
.     * Run cexport
.     if "`varlist'" != "" {
 19.         cexport delimited `varlist' using "`cexport_csv'", `opts'
 20.     }
 21.     else {
 22.         cexport delimited using "`cexport_csv'", `opts'
 23.     }
 24. 
.     * Reimport and compare
.     import delimited using "`stata_csv'", clear
 25.     local stata_n = _N
 26.     local stata_k = c(k)
 27. 
.     import delimited using "`cexport_csv'", clear
 28.     local cexport_n = _N
 29.     local cexport_k = c(k)
 30. 
.     * Cleanup temp files
.     capture erase "`stata_csv'"
 31.     capture erase "`cexport_csv'"
 32. 
.     restore
 33. 
.     * Compare dimensions
.     if `stata_n' == `cexport_n' & `stata_k' == `cexport_k' {
 34.         global TESTS_PASSED = $TESTS_PASSED + 1
 35.         di as result "[PASS] `testname' (N=`stata_n', K=`cexport_k')"
 36.     }
 37.     else {
 38.         global TESTS_FAILED = $TESTS_FAILED + 1
 39.         di as error "[FAIL] `testname' (N: `stata_n'!=`cexport_n', K: `sta
> ta_k'!=`cexport_k')"
 40.     }
 41. end

. 
. /****************************************************************************
> ***
>  * benchmark_binscatter (for cbinscatter validation)
>  *
>  * Compare cbinscatter vs binscatter (if installed)
>  *
>  * Syntax: benchmark_binscatter yvar xvar [, controls(varlist) absorb(varlist
> )
>  *         by(varname) nquantiles(int) testname(string)]
>  ****************************************************************************
> **/
. capture program drop benchmark_binscatter

. program define benchmark_binscatter
  1.     syntax varlist(min=2 max=2) [if] [in] [aw fw pw], [controls(varlist) A
> bsorb(varlist) BY(varname) NQuantiles(integer 20) testname(string) nograph]
  2. 
.     gettoken yvar xvar : varlist
  3. 
.     if "`testname'" == "" local testname "binscatter `yvar' `xvar'"
  4. 
.     global TESTS_TOTAL = $TESTS_TOTAL + 1
  5. 
.     * Build option string
.     local opts "nquantiles(`nquantiles') nograph"
  6.     if "`controls'" != "" local opts "`opts' controls(`controls')"
  7.     if "`absorb'" != "" local opts "`opts' absorb(`absorb')"
  8.     if "`by'" != "" local opts "`opts' by(`by')"
  9. 
.     * Build weight string
.     local wtexp ""
 10.     if "`weight'" != "" local wtexp "[`weight'`exp']"
 11. 
.     preserve
 12. 
.     * Run cbinscatter
.     quietly cbinscatter `yvar' `xvar' `wtexp' `if' `in', `opts'
 13.     local cbin_N = e(N)
 14.     local cbin_nq = e(nquantiles)
 15.     matrix cbin_data = e(bindata)
 16. 
.     restore
 17. 
.     * Verify cbinscatter produced valid results
.     if `cbin_N' > 0 & `cbin_nq' == `nquantiles' {
 18.         global TESTS_PASSED = $TESTS_PASSED + 1
 19.         di as result "[PASS] `testname' (N=`cbin_N', bins=`cbin_nq')"
 20.     }
 21.     else {
 22.         global TESTS_FAILED = $TESTS_FAILED + 1
 23.         di as error "[FAIL] `testname' (N=`cbin_N', bins=`cbin_nq')"
 24.     }
 25. end

. 
. di as text "Benchmark helper programs loaded"
Benchmark helper programs loaded

. 
end of do-file

. 
. di as text ""


. di as text "ctools validation framework loaded"
ctools validation framework loaded

. di as text ""


. 
end of do-file

. 
. di as text ""


. di as text "=================================================================
> ====="
======================================================================

. di as text "              CSORT VALIDATION TEST SUITE"
              CSORT VALIDATION TEST SUITE

. di as text "=================================================================
> ====="
======================================================================

. 
. /****************************************************************************
> ***
>  * Preliminary: Check if csort plugin works
>  ****************************************************************************
> **/
. print_section "Preliminary: Check if csort plugin works"

----------------------------------------------------------------------
Preliminary: Check if csort plugin works
----------------------------------------------------------------------

. 
. sysuse auto, clear
(1978 automobile data)

. capture noisily csort price

. local csort_works = (_rc == 0)

. 
. if !`csort_works' {
.     di as error "  csort plugin is not functioning (rc=`=_rc')"
.     di as error "  Skipping all csort tests"
.     global TESTS_PASSED = 0
.     global TESTS_FAILED = 1
.     global TESTS_TOTAL = 1
.     print_summary "csort"
.     exit 1
. }

. 
. di as result "  csort plugin is functional"
  csort plugin is functional

. global TESTS_PASSED = $TESTS_PASSED + 1

. global TESTS_TOTAL = $TESTS_TOTAL + 1

. 
. /****************************************************************************
> ***
>  * Auto dataset tests
>  ****************************************************************************
> **/
. print_section "Auto dataset"

----------------------------------------------------------------------
Auto dataset
----------------------------------------------------------------------

. 
. sysuse auto, clear
(1978 automobile data)

. 
. * Single numeric variable
. benchmark_sort price, testname("single numeric (price)")
(1978 automobile data)
[PASS] single numeric (price)

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort weight, testname("single numeric (weight)")
(1978 automobile data)
[PASS] single numeric (weight)

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg, testname("single numeric (mpg)")
(1978 automobile data)
[PASS] single numeric (mpg)

. 
. * Single string variable
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("single string (make)")
(1978 automobile data)
[PASS] single string (make)

. 
. * Categorical variable with duplicates
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign, testname("binary with duplicates (foreign)")
(1978 automobile data)
[PASS] binary with duplicates (foreign)

. 
. * Variable with missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missing values (rep78)")
(1978 automobile data)
[PASS] with missing values (rep78)

. 
. * Multi-variable sorts
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign price, testname("two vars (foreign price)")
(1978 automobile data)
[PASS] two vars (foreign price)

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign rep78 price, testname("three vars (foreign rep78 price
> )")
(1978 automobile data)
[PASS] three vars (foreign rep78 price)

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make price, testname("string + numeric (make price)")
(1978 automobile data)
[PASS] string + numeric (make price)

. 
. /****************************************************************************
> ***
>  * Census dataset tests
>  ****************************************************************************
> **/
. print_section "Census dataset"

----------------------------------------------------------------------
Census dataset
----------------------------------------------------------------------

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("state name")
(1980 Census data by state)
[PASS] state name

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort region, testname("region code")
(1980 Census data by state)
[PASS] region code

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort pop, testname("population")
(1980 Census data by state)
[PASS] population

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort region state, testname("region state")
(1980 Census data by state)
[PASS] region state

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort region pop, testname("region pop")
(1980 Census data by state)
[PASS] region pop

. 
. /****************************************************************************
> ***
>  * Synthetic data tests
>  ****************************************************************************
> **/
. print_section "Synthetic data"

----------------------------------------------------------------------
Synthetic data
----------------------------------------------------------------------

. 
. * Large dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen id = _n

. gen group = runiformint(1, 100)

. gen value = runiform()

. gen str20 label = "item" + string(runiformint(1, 500))

. 
. benchmark_sort value, testname("10K random floats")
[PASS] 10K random floats

. 
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen id = _n

. gen group = runiformint(1, 100)

. gen value = runiform()

. gen str20 label = "item" + string(runiformint(1, 500))

. 
. benchmark_sort group, testname("10K random ints")
[PASS] 10K random ints

. 
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen id = _n

. gen group = runiformint(1, 100)

. gen value = runiform()

. gen str20 label = "item" + string(runiformint(1, 500))

. 
. benchmark_sort label, testname("10K random strings")
[PASS] 10K random strings

. 
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen id = _n

. gen group = runiformint(1, 100)

. gen value = runiform()

. gen str20 label = "item" + string(runiformint(1, 500))

. 
. benchmark_sort group value, testname("10K group + value")
[PASS] 10K group + value

. 
. * Negative numbers
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = runiform() * 200 - 100

. 
. benchmark_sort x, testname("negative numbers")
[PASS] negative numbers

. 
. * All same values (degenerate case)
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same values")
[PASS] all same values

. 
. * Already sorted
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = _n

. 
. benchmark_sort x, testname("already sorted")
[PASS] already sorted

. 
. * Reverse sorted
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 1000 - _n

. 
. benchmark_sort x, testname("reverse sorted")
[PASS] reverse sorted

. 
. * Integer edge cases
. clear

. set obs 100
Number of observations (_N) was 0, now 100.

. gen long x = runiformint(-2147483647, 2147483646)

. 
. benchmark_sort x, testname("extreme integers")
[PASS] extreme integers

. 
. * Float precision
. clear

. set obs 100
Number of observations (_N) was 0, now 100.

. gen double x = runiform() * 1e-10

. 
. benchmark_sort x, testname("small floats")
[PASS] small floats

. 
. /****************************************************************************
> ***
>  * Edge cases
>  ****************************************************************************
> **/
. print_section "Edge cases"

----------------------------------------------------------------------
Edge cases
----------------------------------------------------------------------

. 
. * Empty string handling
. clear

. set obs 100
Number of observations (_N) was 0, now 100.

. gen str10 x = ""
(100 missing values generated)

. replace x = "test" if _n > 50
(50 real changes made)

. 
. benchmark_sort x, testname("empty strings")
[PASS] empty strings

. 
. * Very long strings
. clear

. set obs 100
Number of observations (_N) was 0, now 100.

. gen str200 x = "a" * runiformint(1, 200)

. 
. benchmark_sort x, testname("variable length strings")
[PASS] variable length strings

. 
. * Single observation
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single observation")
[PASS] single observation

. 
. * Two observations
. clear

. set obs 2
Number of observations (_N) was 0, now 2.

. gen x = 2 - _n

. 
. benchmark_sort x, testname("two observations")
[PASS] two observations

. 
. /****************************************************************************
> ***
>  * Larger scale tests
>  ****************************************************************************
> **/
. print_section "Larger scale tests"

----------------------------------------------------------------------
Larger scale tests
----------------------------------------------------------------------

. 
. clear

. set seed 54321

. set obs 50000
Number of observations (_N) was 0, now 50,000.

. gen id = _n

. gen group = runiformint(1, 500)

. gen value = rnormal()

. 
. benchmark_sort value, testname("50K random normal")
[PASS] 50K random normal

. 
. clear

. set seed 54321

. set obs 50000
Number of observations (_N) was 0, now 50,000.

. gen id = _n

. gen group = runiformint(1, 500)

. gen value = rnormal()

. 
. benchmark_sort group id, testname("50K group + id")
[PASS] 50K group + id

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: MSD Radix Sort
>  ****************************************************************************
> **/
. print_section "MSD Radix Sort Algorithm"

----------------------------------------------------------------------
MSD Radix Sort Algorithm
----------------------------------------------------------------------

. 
. * Numeric sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort price, testname("numeric") algorithm(msd)
(1978 automobile data)
[PASS] numeric [alg=msd]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg weight, testname("multi-numeric") algorithm(msd)
(1978 automobile data)
[PASS] multi-numeric [alg=msd]

. 
. * String sorting (MSD is optimized for strings)
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("string (make)") algorithm(msd)
(1978 automobile data)
[PASS] string (make) [alg=msd]

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("string (state)") algorithm(msd)
(1980 Census data by state)
[PASS] string (state) [alg=msd]

. 
. * Mixed types
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign make, testname("mixed types") algorithm(msd)
(1978 automobile data)
[PASS] mixed types [alg=msd]

. 
. * With missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missings") algorithm(msd)
(1978 automobile data)
[PASS] with missings [alg=msd]

. 
. * Larger dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen str20 label = "item" + string(runiformint(1, 500))

. gen value = rnormal()

. 
. benchmark_sort label, testname("10K strings") algorithm(msd)
[PASS] 10K strings [alg=msd]

. 
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen str20 label = "item" + string(runiformint(1, 500))

. gen value = rnormal()

. 
. benchmark_sort value, testname("10K numeric") algorithm(msd)
[PASS] 10K numeric [alg=msd]

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: Timsort
>  ****************************************************************************
> **/
. print_section "Timsort Algorithm"

----------------------------------------------------------------------
Timsort Algorithm
----------------------------------------------------------------------

. 
. * Numeric sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort price, testname("numeric") algorithm(timsort)
(1978 automobile data)
[PASS] numeric [alg=timsort]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg weight, testname("multi-numeric") algorithm(timsort)
(1978 automobile data)
[PASS] multi-numeric [alg=timsort]

. 
. * String sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("string (make)") algorithm(timsort)
(1978 automobile data)
[PASS] string (make) [alg=timsort]

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("string (state)") algorithm(timsort)
(1980 Census data by state)
[PASS] string (state) [alg=timsort]

. 
. * Mixed types
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign make, testname("mixed types") algorithm(timsort)
(1978 automobile data)
[PASS] mixed types [alg=timsort]

. 
. * With missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missings") algorithm(timsort)
(1978 automobile data)
[PASS] with missings [alg=timsort]

. 
. * Already sorted (Timsort should excel here)
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. gen x = _n

. 
. benchmark_sort x, testname("already sorted") algorithm(timsort)
[PASS] already sorted [alg=timsort]

. 
. * Reverse sorted
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. gen x = 5000 - _n

. 
. benchmark_sort x, testname("reverse sorted") algorithm(timsort)
[PASS] reverse sorted [alg=timsort]

. 
. * Partially sorted (panel-like data)
. clear

. set seed 99999

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen panel_id = mod(_n - 1, 100) + 1

. gen time = ceil(_n / 100)

. gen value = rnormal()

. sort panel_id  /* Already sorted by panel_id */

. 
. benchmark_sort panel_id time, testname("panel data") algorithm(timsort)
[PASS] panel data [alg=timsort]

. 
. * Larger dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen value = rnormal()

. 
. benchmark_sort value, testname("10K numeric") algorithm(timsort)
[PASS] 10K numeric [alg=timsort]

. 
. /****************************************************************************
> ***
>  * Edge cases for all algorithms
>  ****************************************************************************
> **/
. print_section "Edge cases - all algorithms"

----------------------------------------------------------------------
Edge cases - all algorithms
----------------------------------------------------------------------

. 
. * Single observation
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(lsd)
[PASS] single obs [alg=lsd]

. 
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(msd)
[PASS] single obs [alg=msd]

. 
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(timsort)
[PASS] single obs [alg=timsort]

. 
. * All same values
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(lsd)
[PASS] all same [alg=lsd]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(msd)
[PASS] all same [alg=msd]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(timsort)
[PASS] all same [alg=timsort]

. 
. * Negative numbers
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = runiform() * 200 - 100

. 
. benchmark_sort x, testname("negatives") algorithm(msd)
[PASS] negatives [alg=msd]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = runiform() * 200 - 100

. 
. benchmark_sort x, testname("negatives") algorithm(timsort)
[PASS] negatives [alg=timsort]

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: Sample Sort
>  ****************************************************************************
> **/
. print_section "Sample Sort Algorithm"

----------------------------------------------------------------------
Sample Sort Algorithm
----------------------------------------------------------------------

. 
. * Numeric sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort price, testname("numeric") algorithm(sample)
(1978 automobile data)
[PASS] numeric [alg=sample]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg weight, testname("multi-numeric") algorithm(sample)
(1978 automobile data)
[PASS] multi-numeric [alg=sample]

. 
. * String sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("string (make)") algorithm(sample)
(1978 automobile data)
[PASS] string (make) [alg=sample]

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("string (state)") algorithm(sample)
(1980 Census data by state)
[PASS] string (state) [alg=sample]

. 
. * Mixed types
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign make, testname("mixed types") algorithm(sample)
(1978 automobile data)
[PASS] mixed types [alg=sample]

. 
. * With missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missings") algorithm(sample)
(1978 automobile data)
[PASS] with missings [alg=sample]

. 
. * Larger dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen value = rnormal()

. 
. benchmark_sort value, testname("10K numeric") algorithm(sample)
[PASS] 10K numeric [alg=sample]

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: Counting Sort
>  ****************************************************************************
> **/
. print_section "Counting Sort Algorithm"

----------------------------------------------------------------------
Counting Sort Algorithm
----------------------------------------------------------------------

. 
. * Integer data
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign, testname("binary (0/1)") algorithm(counting)
(1978 automobile data)
[PASS] binary (0/1) [alg=counting]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("small int range") algorithm(counting)
(1978 automobile data)
[PASS] small int range [alg=counting]

. 
. * Year-like data
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. set seed 12345

. gen year = runiformint(1990, 2023)

. benchmark_sort year, testname("year data") algorithm(counting)
[PASS] year data [alg=counting]

. 
. * State codes
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. set seed 54321

. gen state = runiformint(1, 50)

. benchmark_sort state, testname("state codes") algorithm(counting)
[PASS] state codes [alg=counting]

. 
. * Multi-key with integers
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign rep78, testname("multi-int") algorithm(counting)
(1978 automobile data)
[PASS] multi-int [alg=counting]

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: Parallel Merge Sort
>  ****************************************************************************
> **/
. print_section "Parallel Merge Sort Algorithm"

----------------------------------------------------------------------
Parallel Merge Sort Algorithm
----------------------------------------------------------------------

. 
. * Numeric sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort price, testname("numeric") algorithm(merge)
(1978 automobile data)
[PASS] numeric [alg=merge]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg weight, testname("multi-numeric") algorithm(merge)
(1978 automobile data)
[PASS] multi-numeric [alg=merge]

. 
. * String sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("string (make)") algorithm(merge)
(1978 automobile data)
[PASS] string (make) [alg=merge]

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("string (state)") algorithm(merge)
(1980 Census data by state)
[PASS] string (state) [alg=merge]

. 
. * Mixed types
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign make, testname("mixed types") algorithm(merge)
(1978 automobile data)
[PASS] mixed types [alg=merge]

. 
. * With missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missings") algorithm(merge)
(1978 automobile data)
[PASS] with missings [alg=merge]

. 
. * Larger dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen value = rnormal()

. 
. benchmark_sort value, testname("10K numeric") algorithm(merge)
[PASS] 10K numeric [alg=merge]

. 
. /****************************************************************************
> ***
>  * Edge cases for new algorithms
>  ****************************************************************************
> **/
. print_section "Edge cases - new algorithms"

----------------------------------------------------------------------
Edge cases - new algorithms
----------------------------------------------------------------------

. 
. * Single observation
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(sample)
[PASS] single obs [alg=sample]

. 
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(merge)
[PASS] single obs [alg=merge]

. 
. * All same values
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(sample)
[PASS] all same [alg=sample]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(merge)
[PASS] all same [alg=merge]

. 
. /****************************************************************************
> ***
>  * Algorithm-specific tests: IPS4o (In-place Parallel Super Scalar Samplesort
> )
>  ****************************************************************************
> **/
. print_section "IPS4o Algorithm"

----------------------------------------------------------------------
IPS4o Algorithm
----------------------------------------------------------------------

. 
. * Numeric sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort price, testname("numeric") algorithm(ips4o)
(1978 automobile data)
[PASS] numeric [alg=ips4o]

. 
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort mpg weight, testname("multi-numeric") algorithm(ips4o)
(1978 automobile data)
[PASS] multi-numeric [alg=ips4o]

. 
. * String sorting
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort make, testname("string (make)") algorithm(ips4o)
(1978 automobile data)
[PASS] string (make) [alg=ips4o]

. 
. sysuse census, clear
(1980 Census data by state)

. benchmark_sort state, testname("string (state)") algorithm(ips4o)
(1980 Census data by state)
[PASS] string (state) [alg=ips4o]

. 
. * Mixed types
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort foreign make, testname("mixed types") algorithm(ips4o)
(1978 automobile data)
[PASS] mixed types [alg=ips4o]

. 
. * With missing values
. sysuse auto, clear
(1978 automobile data)

. benchmark_sort rep78, testname("with missings") algorithm(ips4o)
(1978 automobile data)
[PASS] with missings [alg=ips4o]

. 
. * Larger dataset
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen value = rnormal()

. 
. benchmark_sort value, testname("10K numeric") algorithm(ips4o)
[PASS] 10K numeric [alg=ips4o]

. 
. clear

. set seed 12345

. set obs 10000
Number of observations (_N) was 0, now 10,000.

. gen str20 label = "item" + string(runiformint(1, 500))

. 
. benchmark_sort label, testname("10K strings") algorithm(ips4o)
[PASS] 10K strings [alg=ips4o]

. 
. * Edge cases for IPS4o
. clear

. set obs 1
Number of observations (_N) was 0, now 1.

. gen x = 42

. 
. benchmark_sort x, testname("single obs") algorithm(ips4o)
[PASS] single obs [alg=ips4o]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = 5

. 
. benchmark_sort x, testname("all same") algorithm(ips4o)
[PASS] all same [alg=ips4o]

. 
. clear

. set obs 1000
Number of observations (_N) was 0, now 1,000.

. gen x = runiform() * 200 - 100

. 
. benchmark_sort x, testname("negatives") algorithm(ips4o)
[PASS] negatives [alg=ips4o]

. 
. * Already sorted (edge case)
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. gen x = _n

. 
. benchmark_sort x, testname("already sorted") algorithm(ips4o)
[PASS] already sorted [alg=ips4o]

. 
. * Reverse sorted
. clear

. set obs 5000
Number of observations (_N) was 0, now 5,000.

. gen x = 5000 - _n

. 
. benchmark_sort x, testname("reverse sorted") algorithm(ips4o)
[PASS] reverse sorted [alg=ips4o]

. 
. /****************************************************************************
> ***
>  * SUMMARY
>  ****************************************************************************
> **/
. print_summary "csort"

----------------------------------------------------------------------
SUMMARY: csort
----------------------------------------------------------------------
Tests passed: 93
Tests failed: 0
Total tests:  93
ALL TESTS PASSED
----------------------------------------------------------------------

. 
. * Return error code if any tests failed
. if $TESTS_FAILED > 0 {
.     exit 1
. }

. 
end of do-file
